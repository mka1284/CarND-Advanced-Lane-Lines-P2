{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "################# * 0. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "\n",
    "def compute_calib_from_chessboards(nx, ny, filename_pattern):\n",
    "    \"\"\"\n",
    "    This function calculates the objectpoints and imagepoints given calibration images containing a chessboard.\n",
    "    Copied/adapted from: https://github.com/udacity/CarND-Camera-Calibration/blob/master/camera_calibration.ipynb\n",
    "    :param nx: chessboard dimension in x\n",
    "    :param ny: chessboard dimension in y\n",
    "    :param filename_pattern: calibration images to take into account\n",
    "    :return: camera matrix and distortion coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d points in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(filename_pattern)\n",
    "\n",
    "    print(\"get_objpoints_imgpoints:filename:\" + filename_pattern)\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            # write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            # cv2.imwrite(write_name, img)\n",
    "\n",
    "            #cv2.imshow('img', img)\n",
    "            #cv2.show()\n",
    "            #cv2.waitKey(500)\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            #plt.waitforbuttonpress()\n",
    "\n",
    "            #plt.close('all')\n",
    "        else:\n",
    "            print(\"warning: chessboard corners not found in file \" + fname)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return mtx, dist, rvecs, tvecs\n",
    "\n",
    "\n",
    "def chessboard_calibration():\n",
    "\n",
    "    #correction coefficients\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "    filename_pattern = 'camera_cal/calibration*.jpg'\n",
    "    mtx, dist, rvecs, tvecs = compute_calib_from_chessboards(nx, ny, filename_pattern)\n",
    "    return mtx, dist, rvecs, tvecs\n",
    "\n",
    "def correct_imgs_in_folder(mtx, dist, rvecs, tvec, folder):\n",
    "    \"\"\"\n",
    "    This functions iterates through a folder and undistorts all images into <folder>_undistorted\n",
    "    :param mtx:\n",
    "    :param dist:\n",
    "    :param rvecs:\n",
    "    :param tvec:\n",
    "    :param folder: the folder where the images to be undistorted are in\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # iterate through all files in the folder and apply the pipeline functions\n",
    "    for filename in os.listdir(folder + \"/\"):\n",
    "        #image = mpimg.imread('camera_cal/' + filename)\n",
    "        image = cv2.imread(folder + \"/\" + filename)\n",
    "        undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "        #plt.figure()\n",
    "        #plt.imshow(final_img)\n",
    "        #plt.title(filename)\n",
    "        cv2.imwrite(folder + '_undistorted/' + filename, undistorted)\n",
    "\n",
    "    return\n",
    "\n",
    "################### End calibration 0.\n",
    "\n",
    "\n",
    "###################* 2. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "def white_yellow_mask(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255].\n",
    "\n",
    "    white_mask = cv2.inRange(hsv, np.array([0, 0, 150]), np.array([179, 25, 255]))\n",
    "    white_image = cv2.bitwise_and(img, img, mask=white_mask)\n",
    "\n",
    "    yellow_mask = cv2.inRange(hsv, np.array([90, 120, 0]), np.array([120, 255, 255]))\n",
    "    yellow_image = cv2.bitwise_and(img, img, mask=yellow_mask)\n",
    "\n",
    "    #combined_mask = cv2.bitwise_or(yellow_mask, white_mask);\n",
    "\n",
    "    final_image = cv2.add(white_image, yellow_image)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "\n",
    "    # defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    # returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def cut_area(img):\n",
    "    \"\"\"\n",
    "    Makes black everything laying outside of the desired area\n",
    "    \"\"\"\n",
    "    # pts â€“ Array of polygons where each polygon is represented as an array of points.\n",
    "    vertices = np.array([[(100, 700), (650, 400), (1200, 700)]], dtype=np.int32)\n",
    "    masked_image = region_of_interest(img, vertices)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def create_binary_image(initial_image):\n",
    "    #plt.imshow(initial_image)\n",
    "    #plt.title('original image')\n",
    "\n",
    "    #white_masked = initial_image\n",
    "    white_yellow_masked = white_yellow_mask(initial_image)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(white_masked)\n",
    "    #plt.title('white mask')\n",
    "\n",
    "    gray_image = grayscale(white_yellow_masked)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(gray_image, cmap='gray')\n",
    "    #plt.title('grayscale')\n",
    "\n",
    "    #blurred_image = gaussian_blur(gray_image, 5)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(blurred_image, cmap='gray')\n",
    "    #plt.title('gaussian_blur')\n",
    "\n",
    "    #canny_image = canny(blurred_image, 50, 150)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(canny_image, cmap='gray')\n",
    "    # plt.title('canny')\n",
    "\n",
    "    cut_image = cut_area(gray_image)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cut_image, cmap='gray')\n",
    "    # plt.title('cut image')\n",
    "\n",
    "    #hough_image, lines = hough_trans(canny_image)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(hough_image)\n",
    "    # plt.title('hough image')\n",
    "\n",
    "    s_thresh_min = 100\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(cut_image)\n",
    "    s_binary[(cut_image >= s_thresh_min) & (cut_image <= s_thresh_max)] = 255\n",
    "\n",
    "    return s_binary\n",
    "\n",
    "################### End thresholded binary image\n",
    "\n",
    "\n",
    "################### 3. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "\n",
    "\n",
    "def determine_perspective_transform_matrix():\n",
    "\n",
    "    #img = mpimg.imread(\"test_images_undistorted/straight_lines1.jpg\")\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "\n",
    "    #img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "\n",
    "    #src = np.float32([corners[0], corners[nx - 1], corners[-1], corners[-nx]])\n",
    "\n",
    "    #src = np.float32([[203,719],[537,491], [1091, 717], [749, 492]])\n",
    "    #dst = np.float32([[203,719],[203,191], [1091, 717], [1091, 192]])\n",
    "\n",
    "    src = np.float32([[203, 719], [537, 491], [1091, 717], [749, 492]])\n",
    "    dst = np.float32([[203, 719], [203, 191], [1091, 717], [1091, 192]])\n",
    "\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result\n",
    "    # again, not exact, but close enough for our purposes\n",
    "\n",
    "    #dst = np.float32([[offset, offset], [img_size[0] - offset, offset], [img_size[0] - offset, img_size[1] - offset], [offset, img_size[1] - offset]])\n",
    "\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    #warped = cv2.warpPerspective(img, M, img_size)\n",
    "\n",
    "    #plt.imshow(warped)\n",
    "    #plt.show()\n",
    "\n",
    "    return M\n",
    "\n",
    "def perspective_transform(img):\n",
    "\n",
    "    if not os.path.isfile('M_pickle.p'):\n",
    "        M = determine_perspective_transform_matrix()\n",
    "        pickle.dump(M, open( \"M_pickle.p\", \"wb\" ))\n",
    "    else:\n",
    "        M = pickle.load(open(\"M_pickle.p\", \"rb\"))\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "\n",
    "    return warped, M\n",
    "\n",
    "################## End perspective transform\n",
    "\n",
    "#################* 4. Detect lane pixels and fit to find the lane boundary.\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0] // 2:, :], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] // 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0] // nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low),\n",
    "                      (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low),\n",
    "                      (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(leftx, lefty, rightx, righty, out_img):\n",
    "    # Find our lane pixels first\n",
    "\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, out_img.shape[0] - 1, out_img.shape[0])\n",
    "\n",
    "\n",
    "    try:\n",
    "        left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1 * ploty ** 2 + 1 * ploty\n",
    "        right_fitx = 1 * ploty ** 2 + 1 * ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 255, 255]\n",
    "    out_img[righty, rightx] = [255, 255, 255]\n",
    "    ploty_int = ploty.astype(int)\n",
    "    left_fitx_int = left_fitx.astype(int)\n",
    "\n",
    "    if not any(left_fitx > out_img.shape[1]):\n",
    "        out_img[ploty.astype(int), left_fitx.astype(int)-1] = [255,0,0]\n",
    "        out_img[ploty.astype(int), left_fitx.astype(int)] = [255, 0, 0]\n",
    "        out_img[ploty.astype(int), left_fitx.astype(int)+1] = [255, 0, 0]\n",
    "\n",
    "    if not any(right_fitx > out_img.shape[1]):\n",
    "        out_img[ploty.astype(int), right_fitx.astype(int)-1] = [255,0,0]\n",
    "        out_img[ploty.astype(int), right_fitx.astype(int)] = [255,0,0]\n",
    "        out_img[ploty.astype(int), right_fitx.astype(int)+1] = [255,0,0]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img, ploty, left_fit, right_fit, left_fitx, right_fitx\n",
    "\n",
    "\n",
    "################ End detect lane pixels\n",
    "\n",
    "################* 5. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "def measure_curvature_pixels(ploty, left_fit, right_fit, xm_per_pix, ym_per_pix):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2 * left_fit[0] * y_eval + left_fit[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit[0])\n",
    "    right_curverad = ((1 + (2 * right_fit[0] * y_eval + right_fit[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit[0])\n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "def measure_curvature_real(leftx, lefty, rightx, righty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(lefty)\n",
    "\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * right_fit_cr[0])\n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "################ End Determination of curvature\n",
    "\n",
    "################ 6. Warp the detected lane boundaries back onto the original image.\n",
    "\n",
    "def warp_back_to_original(warped, left_fitx, right_fitx, ploty, original_img, Minv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_img.shape[1], original_img.shape[0]))\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(original_img, 1, newwarp, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "############### End Warp detected lane boundaries back\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, showimgs=False):\n",
    "\n",
    "    #* 0. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "    if not os.path.isfile('undistort_pickle.p'):\n",
    "        mtx, dist, rvecs, tvec = chessboard_calibration()\n",
    "        pickle.dump([mtx, dist, rvecs, tvec], open( \"undistort_pickle.p\", \"wb\" ))\n",
    "    else:\n",
    "        mtx, dist, rvecs, tvec = pickle.load(open(\"undistort_pickle.p\", \"rb\"))\n",
    "        correct_imgs_in_folder(mtx, dist, rvecs, tvec, 'camera_cal')\n",
    "\n",
    "    #* 1. Apply a distortion correction to raw image\n",
    "    undistorted_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    #* 2. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    binary_img = create_binary_image(undistorted_img)\n",
    "\n",
    "    #* 3. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    perspective_trans_img, M = perspective_transform(binary_img)\n",
    "\n",
    "    #* 4. Detect lane pixels and fit to find the lane boundary.\n",
    "    leftx, lefty, rightx, righty, marked_img = find_lane_pixels(perspective_trans_img)\n",
    "    warped_img_with_lanes, ploty, left_fit, right_fit, left_fitx, right_fitx = fit_polynomial(leftx, lefty, rightx, righty, marked_img)\n",
    "\n",
    "    #* 5. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "    #left_curverad, right_curverad = measure_curvature_pixels(ploty, left_fit, right_fit)\n",
    "    left_curverad, right_curverad = measure_curvature_real(leftx, lefty, rightx, righty)\n",
    "\n",
    "    Minv = np.linalg.inv(M)\n",
    "\n",
    "    #* 6. Warp the detected lane boundaries back onto the original image.\n",
    "    final_img = warp_back_to_original(perspective_trans_img, left_fitx, right_fitx, ploty, undistorted_img, Minv)\n",
    "\n",
    "    #* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "    print(\"Left curverad: {}, right curverad: {}\".format(left_curverad, right_curverad))\n",
    "\n",
    "    if showimgs:\n",
    "\n",
    "        f = plt.figure(figsize=(18, 7))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        p1 = plt.subplot(2, 3, 1)\n",
    "        p1.imshow(img)\n",
    "        p1.set_title(('Original Image'))\n",
    "\n",
    "        p2 = plt.subplot(2, 3, 2)\n",
    "        p2.imshow(undistorted_img)\n",
    "        p2.set_title(('Undistorted Image'))\n",
    "\n",
    "        p2 = plt.subplot(2, 3, 3)\n",
    "        p2.imshow(binary_img, cmap='gray')\n",
    "        p2.set_title(('Binary Image'))\n",
    "\n",
    "        p2 = plt.subplot(2, 3, 4)\n",
    "        p2.imshow(perspective_trans_img, cmap='gray')\n",
    "        p2.set_title(('Perspective Transform'))\n",
    "\n",
    "        p2 = plt.subplot(2, 3, 5)\n",
    "        p2.imshow(warped_img_with_lanes)\n",
    "        p2.set_title(('Detected Lane Pixels'))\n",
    "\n",
    "        p2 = plt.subplot(2, 3, 6)\n",
    "        p2.imshow(final_img)\n",
    "        p2.set_title(('Final Image'))\n",
    "\n",
    "        plt.subplots_adjust(left=0, right=1, top=0.9, bottom=0)\n",
    "        plt.show()\n",
    "\n",
    "    return warped_img_with_lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the pipeline on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'test_images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7c0842f59f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpipeline_on_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-7c0842f59f13>\u001b[0m in \u001b[0;36mpipeline_on_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpipeline_on_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_images/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#filename = \"straight_lines1.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: 'test_images/'"
     ]
    }
   ],
   "source": [
    "def pipeline_on_images():\n",
    "\n",
    "    for filename in os.listdir(\"test_images/\"):\n",
    "\n",
    "        #filename = \"straight_lines1.jpg\"\n",
    "        print(filename)\n",
    "        #image = mpimg.imread('camera_cal/' + filename)\n",
    "        image = mpimg.imread(\"test_images/\" + filename)\n",
    "        final_image = pipeline(image, True)\n",
    "        cv2.imwrite('output_images/' + filename, final_image)\n",
    "\n",
    "    return\n",
    "\n",
    "pipeline_on_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the pipeline on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    result = pipeline(image, \"\", False)\n",
    "    \n",
    "    return result\n",
    "\n",
    "white_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
